# Spark RDD ç»ƒä¹ ä½œä¸šï¼š
# é€‰æ‹©éƒ¨åˆ†æ•°æ®ï¼ˆå¯ä»¥æ˜¯è‡ªæ‹Ÿï¼Œå¯ä»¥æ˜¯é‡‡é›†çš„ï¼Œä¹Ÿå¯ä»¥æ˜¯ç°æœ‰çš„ï¼‰ï¼Œ
# è¿›è¡Œå¤šè§’åº¦æ•°æ®ç»Ÿè®¡åŠåˆ†æï¼Œå¹¶è¿›è¡Œæ•°æ®æ•´åˆåŠå±•ç¤º
# ï¼ˆå°½é‡å¤šçš„è¿ç”¨ Spark RDD APIï¼‰

# è¯´æ˜ï¼šcsvæ–‡ä»¶ä¸ºscrapyçˆ¬è™«ä½œä¸šçˆ¬å–çš„æ¸¸æˆåˆ—è¡¨ğŸ™ƒ
# æ¯ä¸€åˆ—åˆ†åˆ«ä¸ºè‹±æ–‡åã€ä¸­æ–‡åã€å‘è¡Œæ—¥æœŸã€è¯„åˆ†ã€æ¸¸æˆåŸç½‘ç«™ã€ä»·æ ¼ã€steamè´­ä¹°/ä¸‹è½½é“¾æ¥
# English_name ã€Chinese_nameã€release_dateã€scoreã€websiteã€priceã€download_link

from pyspark import SparkContext,SparkConf

# æ„å»º é…ç½®å¯¹è±¡
conf = SparkConf().setAppName('SparkRDDtest').setMaster('local[*]')

# æ„å»º ç¯å¢ƒå¯¹è±¡
sc = SparkContext(conf=conf)

originRDD = sc.textFile('games.csv')

# å°†æ¸¸æˆè‹±æ–‡åå†™å…¥English_name.txtæ–‡ä»¶
file_handle=open('English_name.txt',mode='a+',encoding='utf-8')

# print(originRDD.count())
# print(originRDD.take(2))
for item in originRDD.collect():
    file_handle.write(item[:item.index(',')] + '\n')

file_handle.close()